\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{hyperref}

% Include other packages here, before hyperref.
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

\title{Multi-Layer Perceptron for Diabetes Prediction: An Empirical Study of Network Architecture}

\author{Sadman Sharif\\
Student ID: A1944825\\
University of Adelaide\\
{\tt\small sadman.sharif@student.adelaide.edu.au}
}

\maketitle

%------------------------------------------------------------------------
\section{Introduction}

Diabetes mellitus is a chronic metabolic disorder affecting millions worldwide, making early prediction crucial for preventive healthcare. This work implements and analyzes Multi-Layer Perceptrons (MLPs) for binary classification of diabetes using the Pima Indians Diabetes dataset. The fundamental challenge lies in capturing complex, non-linear relationships between physiological features while maintaining model generalization.

Deep learning, particularly MLPs, offers powerful capabilities for learning hierarchical representations from medical data. The perceptron, as the basic computational unit, transforms inputs through weighted sums and activation functions:
\begin{equation}
y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
\end{equation}
where $x_i$ are inputs, $w_i$ are weights, $b$ is bias, and $f(\cdot)$ is an activation function.

This study systematically explores three MLP architectures: shallow, deep, and wide networks, analyzing their performance trade-offs. Our methodology encompasses comprehensive data preprocessing, including handling biologically implausible zero values, feature standardization, and stratified splitting. The experimental analysis reveals how architectural choices impact model performance, providing insights into optimal network design for medical prediction tasks.

%------------------------------------------------------------------------
\section{Method}

\subsection{Data Preprocessing}

The dataset contains 768 samples with 8 physiological features: pregnancies, glucose, blood pressure, skin thickness, insulin, BMI, diabetes pedigree function, and age. Initial exploration revealed zero values in features where they are biologically impossible (glucose, blood pressure, BMI). These were treated as missing values and imputed using median values from respective feature distributions.

Feature standardization was performed using StandardScaler to normalize inputs to zero mean and unit variance:
\begin{equation}
x' = \frac{x - \mu}{\sigma}
\end{equation}

The dataset was split into training (60\%), validation (20\%), and test (20\%) sets using stratified sampling to preserve class distribution across splits.

\subsection{Network Architecture}

We implemented a flexible MLP architecture using PyTorch, allowing configurable depth and width. The general architecture follows:

\textbf{Input Layer} $\rightarrow$ \textbf{Hidden Layers} $\rightarrow$ \textbf{Output Layer}

Each hidden layer consists of:
\begin{itemize}
\item Linear transformation: $z = Wx + b$
\item ReLU activation: $a = \max(0, z)$
\item Dropout regularization (probability $p$)
\end{itemize}

The output layer uses sigmoid activation for binary classification:
\begin{equation}
\hat{y} = \sigma(w^T h + b) = \frac{1}{1 + e^{-(w^T h + b)}}
\end{equation}

\subsection{Training Procedure}

Training employed Binary Cross-Entropy (BCE) loss:
\begin{equation}
\mathcal{L} = -\frac{1}{N}\sum_{i=1}^{N}[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]
\end{equation}

Optimization used Adam optimizer with adaptive learning rates. Dropout regularization prevented overfitting, with rates adjusted based on network complexity. Training ran for 100 epochs with batch size determined experimentally for each architecture.

%------------------------------------------------------------------------
\section{Experimental Analysis}

\subsection{Experimental Setup}

Three distinct architectures were evaluated to understand the impact of network depth and width:

\begin{table}[h]
\centering
\caption{Network Configurations}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Experiment} & \textbf{Architecture} & \textbf{Parameters} \\
\midrule
Shallow & [32] & 297 \\
Deep & [64, 32, 16] & 3,041 \\
Wide & [128, 64] & 9,345 \\
\bottomrule
\end{tabular}
\end{table}

Hyperparameters were tuned individually:
\begin{itemize}
\item \textbf{Shallow}: LR=0.001, batch=32, dropout=0.2
\item \textbf{Deep}: LR=0.001, batch=32, dropout=0.3
\item \textbf{Wide}: LR=0.0005, batch=64, dropout=0.25
\end{itemize}

\subsection{Performance Analysis}

\begin{table}[h]
\centering
\caption{Test Set Performance Metrics}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Model} & \textbf{Acc.} & \textbf{Prec.} & \textbf{Rec.} & \textbf{F1} \\
\midrule
Shallow & 0.753 & 0.694 & 0.556 & 0.617 \\
Deep & \textbf{0.779} & \textbf{0.750} & 0.583 & \textbf{0.656} \\
Wide & 0.766 & 0.714 & \textbf{0.611} & 0.659 \\
\bottomrule
\end{tabular}
\end{table}

The deep network achieved highest accuracy (77.9\%), demonstrating benefits of hierarchical feature learning. Training curves revealed:

\begin{itemize}
\item \textbf{Shallow network}: Fast convergence but limited capacity, plateauing early with potential underfitting
\item \textbf{Deep network}: Gradual improvement with better feature abstraction, balanced bias-variance trade-off
\item \textbf{Wide network}: Higher initial loss, slower convergence, signs of mild overfitting despite regularization
\end{itemize}

\subsection{Key Findings}

\textbf{1. Depth vs Width Trade-off:} The 3-layer deep network outperformed the 2-layer wide network despite having fewer parameters (3,041 vs 9,345), suggesting depth enables more efficient feature hierarchies for this medical dataset.

\textbf{2. Regularization Impact:} Higher dropout rates (0.3 for deep network) effectively prevented overfitting in complex architectures, while maintaining model capacity.

\textbf{3. Class Imbalance Challenge:} All models showed lower recall than precision, indicating difficulty detecting positive diabetes cases. The dataset's 35\% positive class rate suggests potential benefits from class weighting or resampling strategies.

\textbf{4. Feature Importance:} Correlation analysis revealed glucose level and BMI as strongest predictors, aligning with medical literature on diabetes risk factors.

%------------------------------------------------------------------------
\section{Conclusion}

This study demonstrated that moderate-depth MLPs (3 hidden layers) provide optimal performance for diabetes prediction, achieving 77.9\% accuracy. The deep architecture effectively captured non-linear relationships between physiological features while maintaining generalization through appropriate regularization.

Key insights include the superiority of depth over width for medical data, the critical role of proper data preprocessing (especially handling missing values), and the persistent challenge of class imbalance in medical prediction tasks.

Future improvements could explore ensemble methods, advanced regularization techniques like batch normalization, and addressing class imbalance through SMOTE or weighted loss functions. The modular implementation facilitates such extensions while maintaining reproducibility.

{\small
\bibliographystyle{ieee_fullname}
\bibliography{references}
}

% References (example - replace with actual references)
\begin{thebibliography}{9}

\bibitem{diabetes2020}
American Diabetes Association.
\newblock Classification and diagnosis of diabetes: Standards of medical care in diabetesâ€”2020.
\newblock {\em Diabetes Care}, 43(Supplement 1):S14--S31, 2020.

\bibitem{goodfellow2016}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock {\em Deep Learning}.
\newblock MIT Press, 2016.

\bibitem{pima1988}
Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., Johannes, R.S.
\newblock Using the ADAP learning algorithm to forecast the onset of diabetes mellitus.
\newblock In {\em Proceedings of the Annual Symposium on Computer Application in Medical Care}, pages 261--265, 1988.

\bibitem{kingma2014}
Diederik P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{srivastava2014}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research}, 15(1):1929--1958, 2014.

\end{thebibliography}

\end{document}
